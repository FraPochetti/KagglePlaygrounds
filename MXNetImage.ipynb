{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. https://mxnet.incubator.apache.org/versions/master/tutorials/python/data_augmentation.html\n",
    "2. https://stackoverflow.com/questions/48957333/does-mxnet-read-training-data-from-s3-in-a-streaming-fashion\n",
    "3. https://mxnet.incubator.apache.org/api/python/image/image.html?highlight=imagedetiter#mxnet.image.ImageDetIter\n",
    "4. https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.datasets.ImageRecordDataset\n",
    "5. https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/data_augmentation.html\n",
    "6. http://d2l.ai/chapter_computer-vision/fine-tuning.html\n",
    "7. https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/\n",
    "8. https://github.com/d2l-ai/d2l-en/blob/master/d2l/utils.py\n",
    "9. http://d2l.ai/chapter_computer-vision/fine-tuning.html\n",
    "\n",
    "\n",
    "* Fail to prepare rec file because some images were corrupted\n",
    "* prepared .lst file manually\n",
    "* command executed to convert images to rec\n",
    "\n",
    "\n",
    "* train on small images and then bigger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:29.845552Z",
     "start_time": "2019-02-05T18:08:28.199875Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon, init, nd, autograd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo\n",
    "from mxnet.gluon import utils as gutils\n",
    "import subprocess\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import mxnet as mx\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import csv\n",
    "\n",
    "#FOLDER = '/Users/francesco/Notebooks/personal/data/movies'\n",
    "FOLDER = '/tmp/data'\n",
    "#BUCKET = 's3://movies-posters-raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:34.137086Z",
     "start_time": "2019-02-05T18:08:33.912797Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39370, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(FOLDER, 'MovieGenre.csv'), encoding='latin1')\n",
    "#df = pd.read_csv(BUCKET+'MovieGenre.csv', encoding='latin1')\n",
    "df = df.drop_duplicates()\n",
    "df = df.loc[~pd.isnull(df.Genre)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:35.367885Z",
     "start_time": "2019-02-05T18:08:35.249748Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>split_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "      <td>[Animation, Adventure, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "      <td>[Action, Adventure, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy|Family|Romance</td>\n",
       "      <td>[Comedy, Family, Romance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Genre                    split_genres\n",
       "0  Animation|Adventure|Comedy  [Animation, Adventure, Comedy]\n",
       "1     Action|Adventure|Family     [Action, Adventure, Family]\n",
       "2              Comedy|Romance               [Comedy, Romance]\n",
       "3        Comedy|Drama|Romance        [Comedy, Drama, Romance]\n",
       "4       Comedy|Family|Romance       [Comedy, Family, Romance]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split_genres'] = df.Genre.str.split('|')\n",
    "df[['Genre', 'split_genres']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:36.844118Z",
     "start_time": "2019-02-05T18:08:36.757340Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_genres</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Animation, Adventure, Comedy]</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Action, Adventure, Family]</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Comedy, Family, Romance]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     split_genres  \\\n",
       "0  [Animation, Adventure, Comedy]   \n",
       "1     [Action, Adventure, Family]   \n",
       "2               [Comedy, Romance]   \n",
       "3        [Comedy, Drama, Romance]   \n",
       "4       [Comedy, Family, Romance]   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df['labels'] = mlb.fit_transform(df.split_genres).tolist()\n",
    "df[['split_genres', 'labels']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:39.940523Z",
     "start_time": "2019-02-05T18:08:39.936533Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28,),\n",
       " array(['Action', 'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy',\n",
       "        'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir',\n",
       "        'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery',\n",
       "        'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
       "        'Talk-Show', 'Thriller', 'War', 'Western'], dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_.shape, mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:22:53.872114Z",
     "start_time": "2019-02-04T15:21:50.794312Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['lst_labels'] = df.labels.apply(lambda x: '\\t'.join([str(i) for i in x]))\n",
    "df['abs_path'] = df.imdbId.apply(lambda x: os.path.join(FOLDER, 'posters', str(x) + '.jpg'))\n",
    "df['check'] = df.abs_path.apply(lambda x: 0 if cv2.imread(x) is None else 1)\n",
    "df['path'] = df.imdbId.astype(str) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:22:53.897093Z",
     "start_time": "2019-02-04T15:22:53.873459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[df.check == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:28:03.507971Z",
     "start_time": "2019-02-04T15:28:03.491724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train = df[['imdbId', 'lst_labels', 'path']].sample(int(len(df)*.8), random_state=42)\n",
    "raw_valid = df[['imdbId', 'lst_labels', 'path']].loc[~df.index.isin(raw_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:22:53.920096Z",
     "start_time": "2019-02-04T15:22:53.915906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_lst(x, name):\n",
    "    x.to_csv(os.path.join(FOLDER, 'temp.lst'), index=False, header=None, sep='\\t')\n",
    "    \n",
    "    with open(os.path.join(FOLDER, 'temp.lst'), \"rt\") as fin:\n",
    "        with open(os.path.join(FOLDER, name), \"wt\") as fout:\n",
    "            for line in fin:\n",
    "                fout.write(line.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:24:33.665750Z",
     "start_time": "2019-02-04T15:24:33.662255Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30838, 3), (7710, 12))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.shape, raw_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:28:06.614469Z",
     "start_time": "2019-02-04T15:28:06.475535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_lst(raw_train, 'train.lst')\n",
    "save_lst(raw_valid, 'valid.lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T19:46:01.711298Z",
     "start_time": "2019-02-04T19:46:01.576949Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474276\t1\t0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1474276.jpg\n",
      "438427\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t438427.jpg\n",
      "357668\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t357668.jpg\n",
      "79839\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t79839.jpg\n",
      "380485\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t380485.jpg\n",
      "118688\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t118688.jpg\n",
      "52844\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t52844.jpg\n",
      "2072933\t0\t0\t0\t0\t0\t1\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t2072933.jpg\n",
      "1092006\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1092006.jpg\n",
      "351795\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t351795.jpg\n"
     ]
    }
   ],
   "source": [
    "! head /Users/francesco/Notebooks/personal/data/movies/train.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:21:13.435448Z",
     "start_time": "2019-02-04T15:21:13.433338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# python /Users/francesco/anaconda3/envs/fraenv37/lib/python3.6/site-packages/mxnet/tools/im2rec.py train.lst posters/ --pack-label\n",
    "# python /Users/francesco/anaconda3/envs/fraenv37/lib/python3.6/site-packages/mxnet/tools/im2rec.py valid.lst posters/ --pack-label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:31.635666Z",
     "start_time": "2019-02-05T18:42:31.624008Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_aug_transform(data, label):\n",
    "    data = data.astype('float32')/255\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3,64,64),\n",
    "                                    rand_crop=0.5, rand_mirror=True, inter_method=10,\n",
    "                                    brightness=0.125, contrast=0.125, saturation=0.125,\n",
    "                                    pca_noise=0.02, mean=mx.nd.array([0.485, 0.456, 0.406]), \n",
    "                                    std=mx.nd.array([0.229, 0.224, 0.225]))\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, label\n",
    "\n",
    "def valid_aug_transform(data, label):\n",
    "    data = data.astype('float32')/255\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3,64,64),\n",
    "                                    mean=mx.nd.array([0.485, 0.456, 0.406]), \n",
    "                                    std=mx.nd.array([0.229, 0.224, 0.225]))\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, label\n",
    "\n",
    "def standard_transform(data, label):\n",
    "    data = data.astype('float32')\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3, 224, 224))\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    return data, label\n",
    "\n",
    "def plot_mx_array(array):\n",
    "    \"\"\"\n",
    "    Array expected to be height x width x 3 (channels), and values are floats between 0 and 255.\n",
    "    \"\"\"\n",
    "    assert array.shape[2] == 3, \"RGB Channel should be last\"\n",
    "    imshow((array.clip(0, 255)/255).asnumpy())\n",
    "    \n",
    "def show_batch(rec_file):\n",
    "    dataset = mx.gluon.data.vision.ImageRecordDataset(os.path.join(FOLDER, rec_file),\n",
    "                                                     transform=standard_transform)\n",
    "    loader = mx.gluon.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    x, y = next(iter(loader))\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        im = (x[i])\n",
    "        id_l = y[i].asnumpy().nonzero()[0]\n",
    "        labels = mlb.classes_[id_l]\n",
    "        title = '/'.join(labels.tolist())\n",
    "        ax.set_title(title)\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow((im.clip(0, 255)/255).asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:33.608848Z",
     "start_time": "2019-02-05T18:42:33.565258Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = mx.gluon.data.vision.ImageRecordDataset(os.path.join(FOLDER, 'train.rec'), \n",
    "                                                           transform=train_aug_transform)\n",
    "\n",
    "validation_dataset = mx.gluon.data.vision.ImageRecordDataset(os.path.join(FOLDER, 'valid.rec'), \n",
    "                                                            transform=valid_aug_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:34.884034Z",
     "start_time": "2019-02-05T18:42:34.879700Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_iter = mx.gluon.data.DataLoader(training_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:36.631456Z",
     "start_time": "2019-02-05T18:42:36.252526Z"
    }
   },
   "outputs": [],
   "source": [
    "#for x, y in train_iter:\n",
    "#    print(x.shape, y.shape)\n",
    "    #assert batch.data[0].shape == (1, 3, 224, 224)\n",
    "    #assert batch.label[0].shape == (28,)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T09:29:40.876870Z",
     "start_time": "2019-02-05T09:29:40.490526Z"
    }
   },
   "outputs": [],
   "source": [
    "#x, y = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:49:11.483030Z",
     "start_time": "2019-02-05T15:49:11.479950Z"
    }
   },
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:48.219279Z",
     "start_time": "2019-02-05T18:42:47.442331Z"
    }
   },
   "outputs": [],
   "source": [
    "#show_batch('valid.rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:43:30.510960Z",
     "start_time": "2019-02-05T18:43:30.409005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/models/resnet18_v2-a81db45f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v2-a81db45f.zip...\n"
     ]
    }
   ],
   "source": [
    "pretrained_net = model_zoo.vision.resnet18_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:43:32.143957Z",
     "start_time": "2019-02-05T18:43:32.130189Z"
    }
   },
   "outputs": [],
   "source": [
    "finetune_net = model_zoo.vision.resnet18_v2(classes=28)\n",
    "finetune_net.features = pretrained_net.features\n",
    "finetune_net.output.initialize(init.Xavier())\n",
    "finetune_net.output.collect_params().setattr('lr_mult', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:50:21.837594Z",
     "start_time": "2019-02-05T18:50:21.827369Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [mx.cpu()] if there is no GPU.\"\"\"\n",
    "    ctxes = []\n",
    "    try:\n",
    "        for i in range(16):\n",
    "            ctx = mx.gpu(i)\n",
    "            _ = nd.array([0], ctx=ctx)\n",
    "            ctxes.append(ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        pass\n",
    "    if not ctxes:\n",
    "        ctxes = [mx.cpu()]\n",
    "    return ctxes\n",
    "\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs):\n",
    "    \"\"\"Train and evaluate a model.\"\"\"\n",
    "    print('training on', ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            Xs, ys, batch_size = _get_batch(batch, ctx)\n",
    "            ls = []\n",
    "            with autograd.record():\n",
    "                y_hats = [net(X) for X in Xs]\n",
    "                ls = [loss(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += sum([l.sum().asscalar() for l in ls])\n",
    "            n += sum([l.size for l in ls])\n",
    "            train_acc_sum += sum([(sig(y_hat) == y).sum().asscalar()\n",
    "                                 for y_hat, y in zip(y_hats, ys)])\n",
    "            m += sum([y.size for y in ys])\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / m, test_acc,\n",
    "                 time.time() - start))\n",
    "\n",
    "def sig(x):\n",
    "    return mx.nd.sigmoid(x) > 0.5\n",
    "    \n",
    "        \n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (sig(net(X)) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T19:18:26.858289Z",
     "start_time": "2019-02-05T19:18:26.853277Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=4):\n",
    "    \n",
    "    train_iter = mx.gluon.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = mx.gluon.data.DataLoader(validation_dataset, batch_size=batch_size)\n",
    "\n",
    "    ctx = mx.gpu()\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    net.hybridize()\n",
    "    loss = gloss.SigmoidBinaryCrossEntropyLoss()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate, 'wd': 0.001})\n",
    "    train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:44:56.909092Z",
     "start_time": "2019-02-05T18:44:56.904752Z"
    }
   },
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:43:36.572867Z",
     "start_time": "2019-02-05T18:43:36.569318Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = mx.ndarray.random.uniform(shape=(128, 3, 64, 64)).copyto(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mx.nd.sigmoid(finetune_net(X)[0]) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:45:23.815723Z",
     "start_time": "2019-02-05T18:45:23.809159Z"
    }
   },
   "outputs": [],
   "source": [
    "#y_hat = finetune_net(x); y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:45:46.857304Z",
     "start_time": "2019-02-05T18:45:46.853304Z"
    }
   },
   "outputs": [],
   "source": [
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:41:54.710065Z",
     "start_time": "2019-02-05T15:41:54.706095Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = finetune_net.features[1](X); X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-05T19:18:29.729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 0.3492, train acc 0.920, test acc 0.923, time 117.8 sec\n",
      "epoch 2, loss 0.2208, train acc 0.923, test acc 0.923, time 111.1 sec\n",
      "epoch 3, loss 0.2208, train acc 0.923, test acc 0.923, time 112.8 sec\n",
      "epoch 4, loss 0.2191, train acc 0.923, test acc 0.923, time 112.4 sec\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(finetune_net, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_fine_tuning(finetune_net, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_fine_tuning(finetune_net, 0.01, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnettrain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_input_dirs = 's3://movies-posters-raw' #'/tmp/data'\n",
    "hyperparameters = {'batch_size': 128, 'epochs': 5, 'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(channel_input_dirs, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet as MXNetEstimator\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNetEstimator(entry_point='mxnettrain.py', \n",
    "            role=sagemaker.get_execution_role(), \n",
    "            train_instance_count=1, \n",
    "            framework_version=1.3,\n",
    "            train_instance_type='ml.p2.xlarge',\n",
    "            hyperparameters = {'batch_size': 128, 'epochs': 10, 'learning_rate': 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2019-02-13-18-15-22-256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-13 18:15:23 Starting - Starting the training job...\n",
      "2019-02-13 18:15:24 Starting - Launching requested ML instances.........\n",
      "2019-02-13 18:16:53 Starting - Preparing the instances for training......\n",
      "2019-02-13 18:17:54 Downloading - Downloading input data...\n",
      "2019-02-13 18:18:49 Training - Training image download completed. Training in progress..\n",
      "\u001b[31m2019-02-13 18:18:49,897 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[31m2019-02-13 18:18:49,939 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_INPUT_DIR': '/opt/ml/input', 'SM_USER_ENTRY_POINT': 'mxnettrain.py', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":10,\"learning_rate\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2019-02-13-18-15-22-256\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-257446244580/sagemaker-mxnet-2019-02-13-18-15-22-256/source/sourcedir.tar.gz\",\"module_name\":\"mxnettrain\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"mxnettrain.py\"}', 'SM_CHANNELS': '[\"training\"]', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NETWORK_INTERFACE_NAME': 'ethwe', 'SM_USER_ARGS': '[\"--batch_size\",\"128\",\"--epochs\",\"10\",\"--learning_rate\",\"0.01\"]', 'SM_NUM_GPUS': '1', 'SM_MODULE_DIR': 's3://sagemaker-eu-west-1-257446244580/sagemaker-mxnet-2019-02-13-18-15-22-256/source/sourcedir.tar.gz', 'SM_HP_BATCH_SIZE': '128', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_HPS': '{\"batch_size\":128,\"epochs\":10,\"learning_rate\":0.01}', 'SM_HP_LEARNING_RATE': '0.01', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_MODULE_NAME': 'mxnettrain', 'SM_HOSTS'\u001b[0m\n",
      "\u001b[31m2019-02-13 18:18:50,388 sagemaker-containers INFO     Module mxnettrain does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-02-13 18:18:50,388 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-02-13 18:18:50,388 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-02-13 18:18:50,388 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: mxnettrain\n",
      "  Running setup.py bdist_wheel for mxnettrain: started\n",
      "  Running setup.py bdist_wheel for mxnettrain: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-IrUhEk/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built mxnettrain\u001b[0m\n",
      "\u001b[31mInstalling collected packages: mxnettrain\u001b[0m\n",
      "\u001b[31mSuccessfully installed mxnettrain-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.0.2 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-02-13 18:18:51,638 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-257446244580/sagemaker-mxnet-2019-02-13-18-15-22-256/source/sourcedir.tar.gz\", \n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    }, \n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ], \n",
      "        \"network_interface_name\": \"ethwe\", \n",
      "        \"current_host\": \"algo-1\"\n",
      "    }, \n",
      "    \"num_cpus\": 4, \n",
      "    \"log_level\": 20, \n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\", \n",
      "    \"input_config_dir\": \"/opt/ml/input/config\", \n",
      "    \"additional_framework_parameters\": {}, \n",
      "    \"output_data_dir\": \"/opt/ml/output/data\", \n",
      "    \"output_dir\": \"/opt/ml/output\", \n",
      "    \"model_dir\": \"/opt/ml/model\", \n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ], \n",
      "    \"master_hostname\": \"algo-1\", \n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10, \n",
      "        \"learning_rate\": 0.01, \n",
      "        \"batch_size\": 128\n",
      "    }, \n",
      "    \"network_interface_name\": \"ethwe\", \n",
      "    \"num_gpus\": 1, \n",
      "    \"input_dir\": \"/opt/ml/input\", \n",
      "    \"user_entry_point\": \"mxnettrain.py\", \n",
      "    \"job_name\": \"sagemaker-mxnet-2019-02-13-18-15-22-256\", \n",
      "    \"current_host\": \"algo-1\", \n",
      "    \"is_master\": true, \n",
      "    \"module_name\": \"mxnettrain\", \n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\", \n",
      "            \"RecordWrapperType\": \"None\", \n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    }, \n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=mxnettrain.py\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=mxnettrain\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":10,\"learning_rate\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2019-02-13-18-15-22-256\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-257446244580/sagemaker-mxnet-2019-02-13-18-15-22-256/source/sourcedir.tar.gz\",\"module_name\":\"mxnettrain\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"mxnettrain.py\"}\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"10\",\"--learning_rate\",\"0.01\"]\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-west-1-257446244580/sagemaker-mxnet-2019-02-13-18-15-22-256/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[31mSM_HPS={\"batch_size\":128,\"epochs\":10,\"learning_rate\":0.01}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_HP_LEARNING_RATE=0.01\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python2.7:/usr/lib/python2.7/plat-x86_64-linux-gnu:/usr/lib/python2.7/lib-tk:/usr/lib/python2.7/lib-old:/usr/lib/python2.7/lib-dynload:/usr/local/lib/python2.7/dist-packages:/usr/lib/python2.7/dist-packages\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m mxnettrain --batch_size 128 --epochs 10 --learning_rate 0.01\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m2019-02-13 18:18:53,498 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-02-13 18:19:00 Uploading - Uploading generated training model\n",
      "2019-02-13 18:19:00 Completed - Training job completed\n",
      "Billable seconds: 67\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(channel_input_dirs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
