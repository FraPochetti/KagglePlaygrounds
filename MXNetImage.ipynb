{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. https://mxnet.incubator.apache.org/versions/master/tutorials/python/data_augmentation.html\n",
    "2. https://stackoverflow.com/questions/48957333/does-mxnet-read-training-data-from-s3-in-a-streaming-fashion\n",
    "3. https://mxnet.incubator.apache.org/api/python/image/image.html?highlight=imagedetiter#mxnet.image.ImageDetIter\n",
    "4. https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.datasets.ImageRecordDataset\n",
    "5. https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/data_augmentation.html\n",
    "6. http://d2l.ai/chapter_computer-vision/fine-tuning.html\n",
    "7. https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/\n",
    "8. https://github.com/d2l-ai/d2l-en/blob/master/d2l/utils.py\n",
    "9. http://d2l.ai/chapter_computer-vision/fine-tuning.html\n",
    "\n",
    "\n",
    "* Fail to prepare rec file because some images were corrupted\n",
    "* prepared .lst file manually\n",
    "* command executed to convert images to rec\n",
    "\n",
    "\n",
    "* train on small images and then bigger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:29.845552Z",
     "start_time": "2019-02-05T18:08:28.199875Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon, init, nd, autograd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo\n",
    "from mxnet.gluon import utils as gutils\n",
    "import subprocess\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import mxnet as mx\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import csv\n",
    "\n",
    "#FOLDER = '/Users/francesco/Notebooks/personal/data/movies'\n",
    "FOLDER = '/tmp/data'\n",
    "#BUCKET = 's3://movies-posters-raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:34.137086Z",
     "start_time": "2019-02-05T18:08:33.912797Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39370, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(FOLDER, 'MovieGenre.csv'), encoding='latin1')\n",
    "#df = pd.read_csv(BUCKET+'MovieGenre.csv', encoding='latin1')\n",
    "df = df.drop_duplicates()\n",
    "df = df.loc[~pd.isnull(df.Genre)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:35.367885Z",
     "start_time": "2019-02-05T18:08:35.249748Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>split_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "      <td>[Animation, Adventure, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "      <td>[Action, Adventure, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy|Family|Romance</td>\n",
       "      <td>[Comedy, Family, Romance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Genre                    split_genres\n",
       "0  Animation|Adventure|Comedy  [Animation, Adventure, Comedy]\n",
       "1     Action|Adventure|Family     [Action, Adventure, Family]\n",
       "2              Comedy|Romance               [Comedy, Romance]\n",
       "3        Comedy|Drama|Romance        [Comedy, Drama, Romance]\n",
       "4       Comedy|Family|Romance       [Comedy, Family, Romance]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split_genres'] = df.Genre.str.split('|')\n",
    "df[['Genre', 'split_genres']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:36.844118Z",
     "start_time": "2019-02-05T18:08:36.757340Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_genres</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Animation, Adventure, Comedy]</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Action, Adventure, Family]</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Comedy, Family, Romance]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     split_genres  \\\n",
       "0  [Animation, Adventure, Comedy]   \n",
       "1     [Action, Adventure, Family]   \n",
       "2               [Comedy, Romance]   \n",
       "3        [Comedy, Drama, Romance]   \n",
       "4       [Comedy, Family, Romance]   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df['labels'] = mlb.fit_transform(df.split_genres).tolist()\n",
    "df[['split_genres', 'labels']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:08:39.940523Z",
     "start_time": "2019-02-05T18:08:39.936533Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28,),\n",
       " array(['Action', 'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy',\n",
       "        'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir',\n",
       "        'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery',\n",
       "        'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
       "        'Talk-Show', 'Thriller', 'War', 'Western'], dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_.shape, mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:22:53.872114Z",
     "start_time": "2019-02-04T15:21:50.794312Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['lst_labels'] = df.labels.apply(lambda x: '\\t'.join([str(i) for i in x]))\n",
    "df['abs_path'] = df.imdbId.apply(lambda x: os.path.join(FOLDER, 'posters', str(x) + '.jpg'))\n",
    "df['check'] = df.abs_path.apply(lambda x: 0 if cv2.imread(x) is None else 1)\n",
    "df['path'] = df.imdbId.astype(str) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:22:53.897093Z",
     "start_time": "2019-02-04T15:22:53.873459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[df.check == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:28:03.507971Z",
     "start_time": "2019-02-04T15:28:03.491724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train = df[['imdbId', 'lst_labels', 'path']].sample(int(len(df)*.8), random_state=42)\n",
    "raw_valid = df[['imdbId', 'lst_labels', 'path']].loc[~df.index.isin(raw_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:22:53.920096Z",
     "start_time": "2019-02-04T15:22:53.915906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_lst(x, name):\n",
    "    x.to_csv(os.path.join(FOLDER, 'temp.lst'), index=False, header=None, sep='\\t')\n",
    "    \n",
    "    with open(os.path.join(FOLDER, 'temp.lst'), \"rt\") as fin:\n",
    "        with open(os.path.join(FOLDER, name), \"wt\") as fout:\n",
    "            for line in fin:\n",
    "                fout.write(line.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:24:33.665750Z",
     "start_time": "2019-02-04T15:24:33.662255Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30838, 3), (7710, 12))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.shape, raw_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:28:06.614469Z",
     "start_time": "2019-02-04T15:28:06.475535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_lst(raw_train, 'train.lst')\n",
    "save_lst(raw_valid, 'valid.lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T19:46:01.711298Z",
     "start_time": "2019-02-04T19:46:01.576949Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474276\t1\t0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1474276.jpg\n",
      "438427\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t438427.jpg\n",
      "357668\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t357668.jpg\n",
      "79839\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t79839.jpg\n",
      "380485\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t380485.jpg\n",
      "118688\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t118688.jpg\n",
      "52844\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t52844.jpg\n",
      "2072933\t0\t0\t0\t0\t0\t1\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t2072933.jpg\n",
      "1092006\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1092006.jpg\n",
      "351795\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t351795.jpg\n"
     ]
    }
   ],
   "source": [
    "! head /Users/francesco/Notebooks/personal/data/movies/train.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:21:13.435448Z",
     "start_time": "2019-02-04T15:21:13.433338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# python /Users/francesco/anaconda3/envs/fraenv37/lib/python3.6/site-packages/mxnet/tools/im2rec.py train.lst posters/ --pack-label\n",
    "# python /Users/francesco/anaconda3/envs/fraenv37/lib/python3.6/site-packages/mxnet/tools/im2rec.py valid.lst posters/ --pack-label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:31.635666Z",
     "start_time": "2019-02-05T18:42:31.624008Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_aug_transform(data, label):\n",
    "    data = data.astype('float32')/255\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3,128,128),\n",
    "                                    rand_crop=0.5, rand_mirror=True, inter_method=10,\n",
    "                                    brightness=0.125, contrast=0.125, saturation=0.125,\n",
    "                                    pca_noise=0.02, mean=mx.nd.array([0.485, 0.456, 0.406]), \n",
    "                                    std=mx.nd.array([0.229, 0.224, 0.225]))\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, label\n",
    "\n",
    "def valid_aug_transform(data, label):\n",
    "    data = data.astype('float32')/255\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3,128,128),\n",
    "                                    mean=mx.nd.array([0.485, 0.456, 0.406]), \n",
    "                                    std=mx.nd.array([0.229, 0.224, 0.225]))\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, label\n",
    "\n",
    "def standard_transform(data, label):\n",
    "    data = data.astype('float32')\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3, 224, 224))\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    return data, label\n",
    "\n",
    "def plot_mx_array(array):\n",
    "    \"\"\"\n",
    "    Array expected to be height x width x 3 (channels), and values are floats between 0 and 255.\n",
    "    \"\"\"\n",
    "    assert array.shape[2] == 3, \"RGB Channel should be last\"\n",
    "    imshow((array.clip(0, 255)/255).asnumpy())\n",
    "    \n",
    "def show_batch(rec_file):\n",
    "    dataset = mx.gluon.data.vision.ImageRecordDataset(os.path.join(FOLDER, rec_file),\n",
    "                                                     transform=standard_transform)\n",
    "    loader = mx.gluon.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    x, y = next(iter(loader))\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        im = (x[i])\n",
    "        id_l = y[i].asnumpy().nonzero()[0]\n",
    "        labels = mlb.classes_[id_l]\n",
    "        title = '/'.join(labels.tolist())\n",
    "        ax.set_title(title)\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow((im.clip(0, 255)/255).asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:33.608848Z",
     "start_time": "2019-02-05T18:42:33.565258Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = mx.gluon.data.vision.ImageRecordDataset(os.path.join(FOLDER, 'train.rec'), \n",
    "                                                           transform=train_aug_transform)\n",
    "\n",
    "validation_dataset = mx.gluon.data.vision.ImageRecordDataset(os.path.join(FOLDER, 'valid.rec'), \n",
    "                                                            transform=valid_aug_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:34.884034Z",
     "start_time": "2019-02-05T18:42:34.879700Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_iter = mx.gluon.data.DataLoader(training_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:36.631456Z",
     "start_time": "2019-02-05T18:42:36.252526Z"
    }
   },
   "outputs": [],
   "source": [
    "#for x, y in train_iter:\n",
    "#    print(x.shape, y.shape)\n",
    "    #assert batch.data[0].shape == (1, 3, 224, 224)\n",
    "    #assert batch.label[0].shape == (28,)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T09:29:40.876870Z",
     "start_time": "2019-02-05T09:29:40.490526Z"
    }
   },
   "outputs": [],
   "source": [
    "#x, y = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:49:11.483030Z",
     "start_time": "2019-02-05T15:49:11.479950Z"
    }
   },
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:42:48.219279Z",
     "start_time": "2019-02-05T18:42:47.442331Z"
    }
   },
   "outputs": [],
   "source": [
    "#show_batch('valid.rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:43:30.510960Z",
     "start_time": "2019-02-05T18:43:30.409005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/models/resnet18_v2-a81db45f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v2-a81db45f.zip...\n"
     ]
    }
   ],
   "source": [
    "pretrained_net = model_zoo.vision.resnet18_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:43:32.143957Z",
     "start_time": "2019-02-05T18:43:32.130189Z"
    }
   },
   "outputs": [],
   "source": [
    "finetune_net = model_zoo.vision.resnet18_v2(classes=28)\n",
    "finetune_net.features = pretrained_net.features\n",
    "finetune_net.output.initialize(init.Xavier())\n",
    "# The model parameters in output will be updated using a learning rate ten\n",
    "# times greater\n",
    "finetune_net.output.collect_params().setattr('lr_mult', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:50:21.837594Z",
     "start_time": "2019-02-05T18:50:21.827369Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [mx.cpu()] if there is no GPU.\"\"\"\n",
    "    ctxes = []\n",
    "    try:\n",
    "        for i in range(16):\n",
    "            ctx = mx.gpu(i)\n",
    "            _ = nd.array([0], ctx=ctx)\n",
    "            ctxes.append(ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        pass\n",
    "    if not ctxes:\n",
    "        ctxes = [mx.cpu()]\n",
    "    return ctxes\n",
    "\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"Return features and labels on ctx.\"\"\"\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs):\n",
    "    \"\"\"Train and evaluate a model.\"\"\"\n",
    "    print('training on', ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            Xs, ys, batch_size = _get_batch(batch, ctx)\n",
    "            ls = []\n",
    "            with autograd.record():\n",
    "                y_hats = [net(X) for X in Xs]\n",
    "                ls = [loss(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += sum([l.sum().asscalar() for l in ls])\n",
    "            n += sum([l.size for l in ls])\n",
    "            train_acc_sum += sum([(sig(y_hat) == y).sum().asscalar()\n",
    "                                 for y_hat, y in zip(y_hats, ys)])\n",
    "            m += sum([y.size for y in ys])\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / m, test_acc,\n",
    "                 time.time() - start))\n",
    "\n",
    "def sig(x):\n",
    "    return mx.nd.sigmoid(x) > 0.5\n",
    "    \n",
    "        \n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (sig(net(X)) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T19:18:26.858289Z",
     "start_time": "2019-02-05T19:18:26.853277Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=4):\n",
    "    \n",
    "    train_iter = mx.gluon.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = mx.gluon.data.DataLoader(validation_dataset, batch_size=batch_size)\n",
    "\n",
    "    ctx = mx.gpu()\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    net.hybridize()\n",
    "    loss = gloss.SigmoidBinaryCrossEntropyLoss()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate, 'wd': 0.001})\n",
    "    train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:44:56.909092Z",
     "start_time": "2019-02-05T18:44:56.904752Z"
    }
   },
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:43:36.572867Z",
     "start_time": "2019-02-05T18:43:36.569318Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = mx.ndarray.random.uniform(shape=(128, 3, 64, 64)).copyto(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mx.nd.sigmoid(finetune_net(X)[0]) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:45:23.815723Z",
     "start_time": "2019-02-05T18:45:23.809159Z"
    }
   },
   "outputs": [],
   "source": [
    "#y_hat = finetune_net(x); y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T18:45:46.857304Z",
     "start_time": "2019-02-05T18:45:46.853304Z"
    }
   },
   "outputs": [],
   "source": [
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:41:54.710065Z",
     "start_time": "2019-02-05T15:41:54.706095Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = finetune_net.features[1](X); X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-05T19:18:29.729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 0.2865, train acc 0.907, test acc 0.916, time 114.4 sec\n",
      "epoch 2, loss 0.2460, train acc 0.919, test acc 0.920, time 109.9 sec\n",
      "epoch 3, loss 0.2348, train acc 0.921, test acc 0.922, time 110.9 sec\n",
      "epoch 4, loss 0.2279, train acc 0.923, test acc 0.923, time 111.8 sec\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(finetune_net, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 0.2127, train acc 0.926, test acc 0.926, time 200.9 sec\n",
      "epoch 2, loss 0.2086, train acc 0.927, test acc 0.927, time 194.6 sec\n",
      "epoch 3, loss 0.2059, train acc 0.927, test acc 0.928, time 195.3 sec\n",
      "epoch 4, loss 0.2040, train acc 0.928, test acc 0.928, time 195.1 sec\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(finetune_net, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 0.3207, train acc 0.919, test acc 0.923, time 195.9 sec\n",
      "epoch 2, loss 0.2209, train acc 0.923, test acc 0.923, time 195.7 sec\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(finetune_net, 0.01, num_epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
